{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "transsexual-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.chdir(\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/dscpu/code/Users/Tamilselvan.S/Press Release/Data\")\n",
    "df = pd.read_excel(\"Press release domain.xlsx\", engine = \"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "hispanic-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Language\"] == \"English\"].reset_index(drop = True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "adapted-shark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Date of release</th>\n",
       "      <th>Title / Contents</th>\n",
       "      <th>Issued by</th>\n",
       "      <th>Country</th>\n",
       "      <th>Language</th>\n",
       "      <th>Description</th>\n",
       "      <th>URL</th>\n",
       "      <th>Marketing Contact</th>\n",
       "      <th>E mail for Marketing Contact</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Unique Count</th>\n",
       "      <th>Company</th>\n",
       "      <th>Issued_Short</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corporate Information</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>NTT DATA Ranked No. 8 in Brand Finance's Lates...</td>\n",
       "      <td>NTT DATA</td>\n",
       "      <td>Global</td>\n",
       "      <td>English</td>\n",
       "      <td>TOKYO – Apr 1, 2021 – NTT DATA, a global digit...</td>\n",
       "      <td>https://www.nttdata.com/global/en/media/press-...</td>\n",
       "      <td>Amy Baj</td>\n",
       "      <td>amy.baj@nttdata.com</td>\n",
       "      <td>2021 Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Global (HQ)</td>\n",
       "      <td>Financial Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Corporate Information</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>Effective April 1, 2021: itelligence | NTT DAT...</td>\n",
       "      <td>NTT DATA</td>\n",
       "      <td>Global</td>\n",
       "      <td>English</td>\n",
       "      <td>March 30, 2021\\n itelligence | NTT DATA Busine...</td>\n",
       "      <td>https://us.nttdata.com/en/news/press-release/2...</td>\n",
       "      <td>Amy Baj</td>\n",
       "      <td>amy.baj@nttdata.com</td>\n",
       "      <td>2021 Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Global (HQ)</td>\n",
       "      <td>Media</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Category Date of release  \\\n",
       "0  Corporate Information      2021-04-01   \n",
       "1  Corporate Information      2021-04-01   \n",
       "\n",
       "                                    Title / Contents Issued by Country  \\\n",
       "0  NTT DATA Ranked No. 8 in Brand Finance's Lates...  NTT DATA  Global   \n",
       "1  Effective April 1, 2021: itelligence | NTT DAT...  NTT DATA  Global   \n",
       "\n",
       "  Language                                        Description  \\\n",
       "0  English  TOKYO – Apr 1, 2021 – NTT DATA, a global digit...   \n",
       "1  English  March 30, 2021\\n itelligence | NTT DATA Busine...   \n",
       "\n",
       "                                                 URL Marketing Contact  \\\n",
       "0  https://www.nttdata.com/global/en/media/press-...           Amy Baj   \n",
       "1  https://us.nttdata.com/en/news/press-release/2...           Amy Baj   \n",
       "\n",
       "  E mail for Marketing Contact  Quarter  Unique Count  Company Issued_Short  \\\n",
       "0          amy.baj@nttdata.com  2021 Q1           NaN      NaN  Global (HQ)   \n",
       "1          amy.baj@nttdata.com  2021 Q1           NaN      NaN  Global (HQ)   \n",
       "\n",
       "              Domain  \n",
       "0  Financial Service  \n",
       "1              Media  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "historic-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sentence\"] = df[\"Title / Contents\"] + \" \" + df[\"Description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "residential-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "egyptian-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_list = [\"Manufacturing\", \"Retail\", \"E-commerce\", \"Health\", \"Insurance\", \n",
    "               \"Financial Service\", \"Pharma\", \"Technology\", \"Energy\",\n",
    "              \"Transport And Logistics\", \"Telecom\", \"Media\", \"Hospitality and Tourism\",\n",
    "               \"Automobile\", \"Infrastructure\", \"Real estate\",\"Defence\",\"Government\",\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "younger-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_list = []\n",
    "for i,k in enumerate(domain_list): \n",
    "#     print(k)\n",
    "    tensor = model.encode(domain_list[i],convert_to_tensor=True)\n",
    "    tensor_list.append(tensor)\n",
    "\n",
    "    \n",
    "label_data = pd.DataFrame()\n",
    "label_data[\"Domain\"] = domain_list\n",
    "label_data[\"Domain_embed\"] = tensor_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-landing",
   "metadata": {},
   "source": [
    "##### Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "sapphire-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###EXAMPLE 1\n",
    "\n",
    "\n",
    "# sen = []\n",
    "\n",
    "# sen_embed = model.encode(sen[0], convert_to_tensor=True)\n",
    "\n",
    "# domain_names = []\n",
    "# domain_scores = []\n",
    "# for i,k in zip(label_data[\"Domain\"], label_data[\"Domain_embed\"]):\n",
    "#     score = util.pytorch_cos_sim(sen_embed, k)\n",
    "#     domain_names.append(i)\n",
    "#     domain_scores.append(score)\n",
    "# #     print(i, round(float(score),3))\n",
    "    \n",
    "# score_data = pd.DataFrame()\n",
    "# score_data[\"Domain\"] = domain_names\n",
    "# score_data[\"Score\"] = np.array(domain_scores)\n",
    "# score_data.sort_values(by = \"Score\", ascending = False, inplace=True)\n",
    "# score_data.reset_index(drop = True, inplace = True)\n",
    "# list(score_data[\"Domain\"].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "younger-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DomainClassifier(sen):\n",
    "    sen_embed = model.encode(sen[0], convert_to_tensor=True)\n",
    "\n",
    "    domain_names = []\n",
    "    domain_scores = []\n",
    "    \n",
    "    for i,k in zip(label_data[\"Domain\"], label_data[\"Domain_embed\"]):\n",
    "        score = util.pytorch_cos_sim(sen_embed, k)\n",
    "        domain_names.append(i)\n",
    "        domain_scores.append(score)\n",
    "\n",
    "    score_data = pd.DataFrame()\n",
    "    score_data[\"Domain\"] = domain_names\n",
    "    score_data[\"Score\"] = np.array(domain_scores)\n",
    "    score_data.sort_values(by = \"Score\", ascending = False, inplace=True)\n",
    "    score_data.reset_index(drop = True, inplace = True)\n",
    "    return list(score_data[\"Domain\"].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "earlier-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df[\"Sentence\"].apply(lambda sen:DomainClassifier([sen]))\n",
    "df[\"Domain_Pred\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "biblical-league",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               [Technology, Financial Service, Telecom]\n",
       "1               [Technology, Infrastructure, E-commerce]\n",
       "2                      [Technology, Automobile, Telecom]\n",
       "3               [Financial Service, Technology, Telecom]\n",
       "4               [Technology, Financial Service, Telecom]\n",
       "                             ...                        \n",
       "502    [Automobile, Technology, Transport And Logistics]\n",
       "503             [Financial Service, Technology, Telecom]\n",
       "504             [Technology, Financial Service, Telecom]\n",
       "505             [Financial Service, Technology, Telecom]\n",
       "506             [Technology, Financial Service, Telecom]\n",
       "Name: Sentence, Length: 507, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "minimal-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Domain_Pred_Data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "elementary-palmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "\n",
      "Manufacturing 0.124\n",
      "Retail 0.147\n",
      "E-commerce 0.191\n",
      "Health 0.127\n",
      "Insurance 0.082\n",
      "Financial Service 0.248\n",
      "Pharma 0.135\n",
      "Technology 0.248\n",
      "Energy 0.045\n",
      "Transport And Logistics 0.127\n",
      "Telecom 0.238\n",
      "Media 0.191\n",
      "Hospitality and Tourism 0.056\n",
      "Automobile 0.111\n",
      "Infrastructure 0.135\n",
      "Real estate 0.066\n",
      "Defence 0.113\n",
      "Government 0.097\n"
     ]
    }
   ],
   "source": [
    "###label similarity\n",
    "\n",
    "\n",
    "sen = [\"NTT DATA Ranked No. 8 in Brand Finance's Latest Report TOKYO – Apr 1, 2021 – NTT DATA, \\\n",
    "a global digital business and IT services leader, \\\n",
    "has been ranked the world's eighth most valuable brand among IT services providers, \\\n",
    "according to the Brand Finance IT Services 25 2021 report issued by UK-based Brand Finance, \\\n",
    "the world's leading brand valuation and strategy consultancy.\"]\n",
    "\n",
    "sen_embed = model.encode(sen[0], convert_to_tensor=True)\n",
    "\n",
    "print(\"Scores\")\n",
    "print()\n",
    "for i,k in zip(label_data[\"Domain\"], label_data[\"Domain_embed\"]):\n",
    "    score = util.pytorch_cos_sim(sen_embed, k)\n",
    "    print(i, round(float(score),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "inappropriate-repeat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "\n",
      "Manufacturing 0.207\n",
      "Domain 0.136\n",
      "Retail 0.147\n",
      "E-commerce 0.141\n",
      "Health 0.098\n",
      "Insurance 0.051\n",
      "Financial Service 0.165\n",
      "Pharma 0.083\n",
      "Technology 0.254\n",
      "Energy 0.036\n",
      "Transport And Logistics 0.207\n",
      "Telecom 0.205\n",
      "Media 0.199\n",
      "Hospitality and Tourism 0.025\n"
     ]
    }
   ],
   "source": [
    "###EXAMPLE 2\n",
    "\n",
    "\n",
    "sen = [\" publish Digital Thought Leadership in Automotive today published the white paper regarding \\\n",
    "Digital Thought Leadership in Automotive, which provides a brief on the technical capability of\\\n",
    " within Automotive onboard and offboard areas through a technical overview.\"]\n",
    "\n",
    "sen_embed = model.encode(sen[0], convert_to_tensor=True)\n",
    "\n",
    "print(\"Scores\")\n",
    "print()\n",
    "for i,k in zip(label_data[\"Domain\"], label_data[\"Domain_embed\"]):\n",
    "    score = util.pytorch_cos_sim(sen_embed, k)\n",
    "    print(i, round(float(score),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "threatened-cookie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.056"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "demographic-thing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans\n",
      "  Downloading googletrans-3.0.0.tar.gz (17 kB)\n",
      "Collecting httpx==0.13.3\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 1.2 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting rfc3986<2,>=1.3\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: certifi in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from httpx==0.13.3->googletrans) (2022.6.15)\n",
      "Collecting idna==2.*\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 2.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting httpcore==0.9.*\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 288 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting hstspreload\n",
      "  Downloading hstspreload-2022.12.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 74.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet==3.* in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
      "Requirement already satisfied: sniffio in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from httpx==0.13.3->googletrans) (1.2.0)\n",
      "Collecting h2==3.*\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 284 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting h11<0.10,>=0.8\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 888 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting hpack<4,>=3.0\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting hyperframe<6,>=5.2.0\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for googletrans: filename=googletrans-3.0.0-py3-none-any.whl size=15735 sha256=eb8ba1500b78c19c0d2b785da81650cd9d44914c89308bb8478d754c35373e8f\n",
      "  Stored in directory: /home/azureuser/.cache/pip/wheels/0e/ce/9b/d51de1064911d42480ab6b57fc943ee36572441f27546354e2\n",
      "Successfully built googletrans\n",
      "\u001b[31mERROR: ray 1.13.0 has requirement grpcio<=1.43.0,>=1.28.1, but you'll have grpcio 1.47.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pandas-profiling 3.2.0 has requirement joblib~=1.1.0, but you'll have joblib 0.14.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pandas-profiling 3.2.0 has requirement markupsafe~=2.1.1, but you'll have markupsafe 2.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab-server 2.15.0 has requirement jinja2>=3.0.3, but you'll have jinja2 2.11.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: dask-sql 2022.8.0 has requirement dask[dataframe,distributed]<=2022.8.0,>=2022.3.0, but you'll have dask 2.30.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azureml-contrib-notebook 1.44.0 has requirement nbconvert<6, but you'll have nbconvert 6.5.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azureml-automl-dnn-nlp 1.44.0 has requirement transformers<=4.5.1,>=4.1.0, but you'll have transformers 4.22.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-mgmt-web 7.0.0 has requirement azure-mgmt-core<2.0.0,>=1.3.1, but you'll have azure-mgmt-core 1.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-mgmt-rdbms 10.2.0b3 has requirement azure-mgmt-core<2.0.0,>=1.3.1, but you'll have azure-mgmt-core 1.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-mgmt-network 21.0.1 has requirement azure-mgmt-core<2.0.0,>=1.3.1, but you'll have azure-mgmt-core 1.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-mgmt-containerservice 20.2.0 has requirement azure-mgmt-core<2.0.0,>=1.3.1, but you'll have azure-mgmt-core 1.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-cli 2.39.0 has requirement azure-graphrbac~=0.60.0, but you'll have azure-graphrbac 0.61.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-cli 2.39.0 has requirement azure-mgmt-authorization~=0.61.0, but you'll have azure-mgmt-authorization 2.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-cli 2.39.0 has requirement azure-mgmt-containerregistry==8.2.0, but you'll have azure-mgmt-containerregistry 10.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-cli 2.39.0 has requirement azure-mgmt-keyvault==9.3.0, but you'll have azure-mgmt-keyvault 10.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-cli 2.39.0 has requirement azure-mgmt-network~=20.0.0, but you'll have azure-mgmt-network 21.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-cli 2.39.0 has requirement azure-mgmt-resource==21.1.0b1, but you'll have azure-mgmt-resource 21.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-cli-core 2.39.0 has requirement argcomplete~=1.8, but you'll have argcomplete 2.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-cli-core 2.39.0 has requirement msal==1.18.0b1, but you'll have msal 1.18.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-cli-core 2.39.0 has requirement msal-extensions~=1.0.0, but you'll have msal-extensions 0.3.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: autokeras 1.0.16 has requirement tensorflow<=2.5.0,>=2.3.0, but you'll have tensorflow 2.2.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: rfc3986, idna, hpack, hyperframe, h2, h11, httpcore, hstspreload, httpx, googletrans\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.3\n",
      "    Uninstalling idna-3.3:\n",
      "      Successfully uninstalled idna-3.3\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.13.0\n",
      "    Uninstalling h11-0.13.0:\n",
      "      Successfully uninstalled h11-0.13.0\n",
      "Successfully installed googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2022.12.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
